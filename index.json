[{"authors":["admin"],"categories":null,"content":"Rahul Nair is a Research Staff Member at IBM Research Europe in Dublin. His research interests are in technology and development (societal applications), trusted computing. His expertise is in optimization, machine learning applied across sectors particularly transportation, healthcare, and business computing. He holds a Ph.D. from University of Maryland College Park.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1591351751,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://rahulnair23.github.io/author/rahul-nair/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/rahul-nair/","section":"authors","summary":"Rahul Nair is a Research Staff Member at IBM Research Europe in Dublin. His research interests are in technology and development (societal applications), trusted computing. His expertise is in optimization, machine learning applied across sectors particularly transportation, healthcare, and business computing.","tags":null,"title":"Rahul Nair","type":"authors"},{"authors":[],"categories":[],"content":"Suppose you have a list of objects that you need to iterate over two consecutive items at a time.\nAn old stackoverflow question for this leads to the a quote from the documentation that reads:\n This makes possible an idiom for clustering a data series into n-length groups using zip(*[iter(s)]*n).\n So the solution would be:\nk = [1, 2, 3, 4, 5, 6] list(zip(*[iter(k)]*2)) # [(1, 2), (3, 4), (5, 6)]  That is cryptic! Let\u0026rsquo;s break it down to understand why this works.\n Let\u0026rsquo;s start with the inner most bit. iter simply returns an iterator object. For lists we would normally just write for x in alist to iterate over the list, but under the hood an iterator is defined with each loop fetching the next item using a next call.  \u0026gt;\u0026gt;\u0026gt; iter(k) \u0026lt;list_iterator object at 0x7fcf654c9f28\u0026gt;  Next we consider [iter(k)]*2 - the multiplication here creates a shallow copy of the list.  \u0026gt;\u0026gt;\u0026gt; [iter(k)] * 2 [\u0026lt;list_iterator object at 0x7fcf654c9f28\u0026gt;, \u0026lt;list_iterator object at 0x7fcf654c9f28\u0026gt;]  The star operator * then unpacks the collection as positional arguments to a function which is zip in this case. zip is a handy tool to merge several iterable together.  \u0026gt;\u0026gt;\u0026gt; zip(*[iter(k)] * 2) \u0026lt;zip object at 0x7fcf654de808\u0026gt;  Finally, the list operator just runs through to generate the entire list, giving us the desired output.  \u0026gt;\u0026gt;\u0026gt; list(zip(*[iter(k)] * 2)) [(1, 2), (3, 4), (5, 6)]  What\u0026rsquo;s strange about all this is that it depends on subtle behaviours of the underlying methods. For example, instead of zip(*[iter(k)] * 2) you wrote list(zip(*[iter(k), iter(k)])). You will end up with a different result. The solution depends on the iterators being a shallow copy! Each time any of the iterator is hit, it calls the next call to the function.\nShow, don\u0026rsquo;t tell I\u0026rsquo;d hate to encounter snippets like this in the wild as it places significant cognitive load on people trying to read this. Strange it was included in the official 2.x documentation, thankfully removed from the current versions.\n","date":1597925800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597929195,"objectID":"167dfe6b38b8eb81af9aa439dcb1206c","permalink":"https://rahulnair23.github.io/post/oh-python/","publishdate":"2020-08-20T13:16:40+01:00","relpermalink":"/post/oh-python/","section":"post","summary":"Suppose you have a list of objects that you need to iterate over two consecutive items at a time.\nAn old stackoverflow question for this leads to the a quote from the documentation that reads:","tags":["python"],"title":"Oh Python","type":"post"},{"authors":[],"categories":[],"content":"A 4.2 kilometre road cuts the 2000 acres of Phoenix Park neatly in half. Chesterfield Avenue doesn\u0026rsquo;t have a single pedestrian crossing, yield sign, or any amenity that isn\u0026rsquo;t designed for the car. During regular times, two lanes for the entire length serve as a parking lot. Throughout the park, pedestrians and cyclists have to stop and yield to passing cars. Its a strange hierarchy of movement to have within a park.\nA pandemic-induced change saw the Office of Public Works (OPW) designate two lanes as cycle-only and closure of peripheral gates to vehicles - both steps that brought some measure of traffic calm. The new minister, in opposition to his own department by all accounts, reversed one of these decisions and so its back being a thoroughfare.\nIn all their public communication on why that is, a theme that stands out is their consideration for \u0026ldquo;An Garda Síochána and other key stakeholders\u0026rdquo;. In addition to being the largest walled park in Europe, the park is also home to several institutions. The residence of the Irish president and the U.S. Ambassador, the police headquarters, a hospital, a school, the zoo, cricket clubs, a polo ground, a visitor\u0026rsquo;s center, a nursing home, the Ordinance Survey of Ireland, several gatekeeper houses - some vacant, and a disused fort.\nSo OPW, it would seem in public, is balancing institutional needs with those of the general public. All this takes me to another place and another time.\nThe People\u0026rsquo;s Park Hot and humid air welcome those arriving at Chennai Terminal train station. As transit planners the world over have trouble connecting dots, the nearest suburban train station is a short trek away in Park Station. For a long time, it was a bit of mystery to me why it was called Park Station as all around it was concrete and asphalt.\n That sector of Chennai was the centre of British colonial power who built Fort St. George around the corner. So not to different from Phoenix park really. It was smaller of course, a mere tenth of its Dublin cousin.\nWhat started in 1859 as a 22 acre park with several ponds and green spaces, slowly morphed in the century to follow. It grew to be as large as 112 acres at one point. The city council took over the park in 1866. Several acres were carved out in 1886 for the Victoria Public Hall - built to commemorate Queen Victoria\u0026rsquo;s golden jubilee.\n The Victoria Public Hall that was built on the park ~1888 (source)   Then there were stadiums and sports clubs followed by a convenient fire in 1985 that was the final nail. The small part of the park that does remain is virtually inaccessible by the public and in neglect.\nSo there you have it - a train station named after something that no longer exists. A cautionary tale on when government agencies serve each other rather than the general public. For Dublin, one can only hope that the 14 kilometre wall that keeps the deer in, keeps institutional needs out.\n","date":1594237997,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596718765,"objectID":"1c644ec04b510e626eb419374c547b32","permalink":"https://rahulnair23.github.io/post/on-parks/","publishdate":"2020-07-08T20:53:17+01:00","relpermalink":"/post/on-parks/","section":"post","summary":"A 4.2 kilometre road cuts the 2000 acres of Phoenix Park neatly in half. Chesterfield Avenue doesn\u0026rsquo;t have a single pedestrian crossing, yield sign, or any amenity that isn\u0026rsquo;t designed for the car.","tags":["urban parks","public amenities"],"title":"Urban parks","type":"post"},{"authors":[],"categories":[],"content":"In this post, I\u0026rsquo;ll review a paper from 2018 that deals with generating boolean decision rules and uses column generation. The paper is well worth the read if you are interested in explainable AI models. The work also won the FICO explainability challenge by applying this method to data from the financial services sector.\nSetting Algorithmic decisions - ones where you rely on machines to reach a conclusion - require justification. Why was my loan approval denied? Why was the scan result classified as cancerous? In these and several other critical sectors, simply stating the prediction of a AI system is not enough. The underlying rationale of \u0026ldquo;why\u0026rdquo; is equally important.\nSeveral methods seek to come up with the justification algorithmically (in a field called Explainable AI) and several methods exist that can be distinguished along several dimensions. The main one is scope. The global methods look to explain the entire model, i.e. how does the model behave? This contrasts with local methods that look to explain a single instance, i.e. why was my loan not approved?\nWhen the models are complex, as is often the case, a popular class of methods are surrogate models. The basic goal here is to build a simpler (e.g. linear) version of a complex model, then look to interpret the simpler model in ways we humans can understand. When built for local explanations, these probe the neighborhood of test instance to build a surrogate of the complex model.\nUnfortunately, it is hard to be objective when it comes to explanations. In practice, different methods will result in vastly different explanations for the same instance on the same underlying (complex) model. For minor changes in training samples or an adjustment of parameters, even the same method can give you very different results. Fundamentally, these approaches are limited by design. If you prescribe to the view that a machine learning (ML) model is all but a lossy compressed view on the data, then surrogate models are a lossy compressed view of the ML model. Significant challenges remain in practical deployments.\nAn alternative view, the one described in the paper, is one where the model is directly interpretable. A directly interpretable model is one that can be understood by humans. There are of course, several models like decision trees that fall in this category.\nThe problem Consider a supervised binary classification task. You are given $(X_i, y_i)$ for observations $i = 1,\u0026hellip;, n$, where $X_i$ is the set of features associated with observation $i$ and $y_i$ is the binary outcome label. The task is to build a boolean classifier $\\hat{y}(\\mathbf{x})$ that can be stated as\nif (condition) then (predict True) else (predict False)  where (condition) is of a specific form called a Disjunctive Normal Form (DNF). DNF clauses are OR of ANDs. A DNF clause on when to drink beer would be (mood=HAPPY AND inventory\u0026gt;0) OR (mood=SAD AND inventory\u0026gt;0) OR (temp\u0026gt;15°C).\nFor a dataset there are exponentially many such clauses involving its features. The challenge is to find a relatively compact subset that provides the best prediction accuracy. The condition needs to be compact as overly complex clauses are not interpretable.\nThe model The paper formulates the search for these clauses as a mixed-integer programming problem.\n$P$ denotes the set of positive samples, i.e. the observations where $y_i = 1$ and $Z$ denote negative ones. All features in $X_i$ are assumed to be binary valued. This isn\u0026rsquo;t too restrictive, continuous and categorical data can be encoded this way. There is $K$ a set of (exponentially many) clauses involving features of $X$ and $K_i, K_i\\subseteq K$ is the subset of clauses satisfied by observation $i$.\nThere are two decision variables. First is $w_k$ (for all $k$ in set $K$) - a binary variable on if clause $k$ is selected for the model. Each clause $k$ in $K$ has an associated complexity $c_k$. The second is $\\xi_i$ defined for $i \\in P$ (i.e. for all positive samples) denotes all samples that are classified incorrectly.\nThe objective looks to minimize Hamming loss which is the fraction of misclassified samples. Specifically, this can be written as\n$$ \\min_{\\xi, w} \\color{blue}\\underbrace{\\color{black}\\sum_{i\\in P} \\xi_i}_{\\text{false negatives}} {\\color{black}+} \\color{blue}\\underbrace{\\color{black}\\sum_{i\\in Z}\\sum_{k\\in K_i} w_k}_{\\text{false positives}} $$\nFalse positives add more than \u0026ldquo;one unit\u0026rdquo; if multiple clauses are satisfied. This is\n$$\\begin{aligned} \\mbox{s.t.} \\qquad \u0026amp; \\xi_i + \\sum_{k\\in K_i} w_k \\ge 1 \\qquad \\xi_i \\ge 0, \\qquad i\\in P \\\\\n\u0026amp; \\sum_{k\\in K} c_k w_k \\le C \\\\\n\u0026amp; w_k \\in \\{0, 1\\} \\qquad \\forall k\\in K \\end{aligned} $$\nThe first constraint looks to identify false negatives. It basically says, for each positive sample, either chalk up a false negative ($\\xi_i$) or include a rule that correctly represents this observation (i.e. a clause from the set $K_i$). The second constraint simply bounds the total complexity of the selected rule set to a parameter $C$.\nThe overall problem still remains however, the set $K$ is very large and we\u0026rsquo;d like to avoid having to generate the entire set. This mainly because, it is expensive to generate and solve for all $K$. In any case, only a few $w_k$ will be selected in the final solution, so it makes sense to only look at clauses as needed.\nIn the maximum clique post earlier, this type of exponential growth was addressed using constraint generation. In this work, they follow a column generation procedure - one of generating new variables ($w_k$) as needed. Adding rows and columns to a optimization program are strongly coupled topics. Adding a constraint (row) to a program is the same as adding a variable (column) to its dual.\nThe pricing problem Now to the problem of generating new conjunctive clauses. The sub-problem looks to find the missing clause with the highest reduced cost, i.e. the clause that has the greatest impact on the objective function. This is a heuristic selection and you may have to undo a selection at a later step. But if no missing clause with a negative reduced cost can be found, the procedure terminates with the optimal solution.\nA bit more notation. From the program above, take $\\mu_i$ to be the dual variables associated with the first constraint, and $\\lambda$ be the dual variable for the complexity constraint. Define two sets of decision variables $\\delta_i$ for all observations $i$ and $z_j$ if feature $j\\in J$ is selected in missing constraint. Additionally denote $S_i$ to be a set of zero valued features for sample $i$.\nArmed with this, the sub-problem to identify a clause to include (with the greatest negative reduce cost) can be formulated as:\n$$ \\min_{\\delta, z} \\color{blue}\\underbrace{\\color{black}\\lambda\\left(1+\\sum_{j\\in J}z_j\\right)}_{\\substack{\\text{complexity of new rule}\\\\\\text{in terms of features selected}}} {\\color{black}-} \\color{blue}\\underbrace{\\color{black}\\sum_{i\\in P} \\mu_i \\delta_i}_{\\substack{\\text{how much the new rule}\\\\\\text{improves false negatives}}}{\\color{black}+} \\color{blue}\\underbrace{\\color{black}\\sum_{i\\in Z} \\delta_i}_{\\substack{\\text{how much the new rule}\\\\\\text{hurts false positives}}} $$\n$$\\begin{aligned} \\mbox{s.t.} \\qquad \u0026amp; \\delta_i + z_j\\le 1 \\qquad j\\in S_i, \\qquad i\\in P \\\\\n\u0026amp; \\delta_i \\ge 1- \\sum_{j\\in S_i} z_j \\qquad \\delta_i\\ge 0 \\qquad i\\in Z\\\\\n\u0026amp; \\sum_{j\\in J} z_j \\le D \\\\\n\u0026amp; z_j \\in \\{0, 1\\} \\qquad \\forall j\\in J \\end{aligned} $$\nThe first constraint here says every zero-valued feature in every positive sample - the feature is either selected or the sample satisfies the clause. The next constraint states that the $i$-th negative sample is covered only if no zero-valued feature is selected. The next constraint bounds the complexity and the feature selection variables are restricted to be binary.\nConclusions The method appears to be well suited for transactional-type data, where there are some underlying rules (e.g. a business process) that generates the training data. I leave you with an interesting example. The tic-tac-toe dataset contains all possible board configurations at the end of a tic-tac-toe game and the outcome (if x won or not). The method extracts almost all the rules of the game based on just this data, just missing the diagonal cases. Some of the rules extracted are superfluous.\n  Rules extracted from tic-tac-toe data   As with all things, the approach comes with some limitations. There is a complexity-accuracy tradeoff, expect classifier accuracy to drop. Although in my experiments this was not substantial. The clauses generated are sensitive to the parameter $C$. If you don\u0026rsquo;t have a mechanism to validate the rule set then it is difficult to tune. The method doesn\u0026rsquo;t deal with class-imbalance, so you would need to under/over-sample to get a balanced sample. It would also worthwhile to study clauses generated in the presence of highly correlated features. I expect one of the correlated features to be picked arbitrarily.\nResources A modified implementation of the model is available through the AIX360 toolkit, so you can try it yourself. The differences are documented in another paper. Mainly, it uses a beam search heuristic instead of the pricing problem. Additionally, the complexity clauses are handled through two regularization terms, rather than a constraint.\n","date":1592300772,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593011846,"objectID":"d8ed4442ad6964b17226cdb2f951c022","permalink":"https://rahulnair23.github.io/post/boolean-rules/","publishdate":"2020-06-16T10:46:12+01:00","relpermalink":"/post/boolean-rules/","section":"post","summary":"In this post, I\u0026rsquo;ll review a paper from 2018 that deals with generating boolean decision rules and uses column generation. The paper is well worth the read if you are interested in explainable AI models.","tags":["explainability","AIX360","boolean decision rules","column generation","mixed integer programming"],"title":"Model explanations via column generation","type":"post"},{"authors":[],"categories":[],"content":"Recently, I had the need to compute maximum weighted cliques on very dense large graphs. This is a well studied problem, and a nice survey paper from 90\u0026rsquo;s by Pardalos and Xue gives a good overview of approaches.\nThe problem We are given a graph $G = (V, E)$ which is a set of vertices $V$ and edges $E$. Each vertex has an associated weight $d_i, \\forall i\\in V$. A clique $C$ is a subset of vertices, where all vertices are pairwise connected. A maximum clique is a clique that has largest weight.\nA related notion is of an independent set, which is a subset of vertices $V$ that are pairwise disconnected. A maximum independent set is similarly an independent set with the largest weight.\nSolutions For general graphs, finding the maximum cliques is a hard problem (NP-complete). An integer programming approach that involves edges can be written as:\n$$\\begin{aligned} \\max_x \u0026amp; \\sum_{i\\in V} d_i x_{i}\\\\\n\\mbox{s.t.} \\qquad \u0026amp; x_i + x_j \\le 1 \\quad \\forall (i, j) \\in \\bar{E} \\\\\n\u0026amp; x_i \\in {0, 1} \\qquad \\forall i\\in V \\end{aligned} $$\nwhere $\\bar{E}$ is called the complement edge set that is a set of edges that are missing from the original graph $G$. All the constraint $x_i + x_j \\le 1$ says is if the edge $(i, j)$ is missing then only one node, either $i$ or $j$, can be in the clique. The objective seeks to maximize the weighted of selected nodes.\nAs pointed out in the paper this formulation isn\u0026rsquo;t useful in practice on account of two problems. First, the linear relaxation, one where the integrality constraints $x_i \\in {0, 1}$ is omitted, gives a poor bound. The second is on account of symmetry. Symmetry arises in this context as vertices with the same weight are indistinguishable. So several configurations result in the same optimal solution. Why is this bad? The branch and cut tree cannot prune the search tree as solutions are in various parts of it. One way to remove symmetry is to do lexicographical ordering. An arbitrary order is imposed via additional constraints that cuts of several optimal solutions knowing that at least one optimal solution is valid. There are other methods as well, such as isomorphic pruning, and orbitopal fixing, but we won\u0026rsquo;t get into those here.\nAn alternative formulation The notion of the complement edge set $\\bar{E}$ can be strengthened using independent sets. If you know an independent set, a clique can contain at most one vertex from such a set. To write this as a constraint, one would need to consider maximum independent sets, lest you allow the omitted vertices to be included in the clique. Further, you would need to look at all maximum independent sets that arise in $G$. Assume for a moment that the set of maximum independent sets $\\mathbb{S}$ is known. Then the problem of finding the maximum weighted clique can be written as\n$$\\begin{aligned} \\max_x \u0026amp; \\sum_{i\\in V} d_i x_{i}\\\\\n\\mbox{s.t.} \\qquad \u0026amp; \\sum_{i\\in I} x_i \\le 1 \\quad \\forall I \\in \\mathbb{S} \\\\\n\u0026amp; x_i \\in {0, 1} \\qquad \\forall i\\in V \\end{aligned} $$\nThe objective is the same as before - maximize the total weight of selected nodes. The constraints, one for each maximum independent set, allows only one vertex into the solution. The constraints are tighter than the previous formulation implying that the linear relaxation gives a better bound. For some classes of graphs, namely perfect graphs, omitting the integrality constraints will directly give you integral solutions! The problem however is that there are now an exponential number of constraints (set $\\mathbb{S}$ is very large).\nOne mechanism to deal with too many constraints is use lazy constraints. The idea is to start the optimization with a small set of constraints and then add relevant constraints from the large pool as you go along. The prerequisite is however that such relevant constraints can be generated efficiently.\nHow would this work? A sketch of the solution algorithm looks like this.\n Use a heuristic procedure to generate a set of maximum independent sets ($S$) Solve a linear relaxation on this limited set ($S \\subseteq \\mathbb{S}$) Based on solution, identify new maximum independent sets that would cut the current solution If no such sets exists, we are done (current solution gives the maximum weighted clique) If there are, then add to the constraints and goto step 2.  Reference implementation To test this, we use the networkx library for graphs and the CPLEX solver. We use one of the many generators for a test graph with a known number of cliques.\nfrom networkx import nx G = nx.generators.ring_of_cliques(6, 3) nx.draw(G, with_labels=True)  gives you this:\n  An test graph with known max cliques   (Step 1) Generating maximum independent sets Here we use the greedy heuristic implementation as shown in this blog:\ndef greedy_init(G): \u0026quot;\u0026quot;\u0026quot; https://kmutya.github.io/maxclique/ \u0026quot;\u0026quot;\u0026quot; n = G.number_of_nodes() # Storing total number of nodes in 'n' max_ind_sets = [] # initializing a list that will store maximum independent sets for j in G.nodes: R = G.copy() # Storing a copy of the graph as a residual neigh = [n for n in R.neighbors(j)] # Catch all the neighbours of j R.remove_node(j) # removing the node we start from iset = [j] R.remove_nodes_from(neigh) # Removing the neighbours of j if R.number_of_nodes() != 0: x = get_min_degree_vertex(R) while R.number_of_nodes() != 0: neigh2 = [m for m in R.neighbors(x)] R.remove_node(x) iset.append(x) R.remove_nodes_from(neigh2) if R.number_of_nodes() != 0: x = get_min_degree_vertex(R) max_ind_sets.append(iset) return(max_ind_sets) def get_min_degree_vertex(Residual_graph): '''Takes in the residual graph R and returns the node with the lowest degree''' degrees = [val for (node, val) in Residual_graph.degree()] node = [node for (node, val) in Residual_graph.degree()] node_degree = dict(zip(node, degrees)) return (min(node_degree, key=node_degree.get))  (Step 2) The optimization model Now we define the optimization model as a linear program using the CPLEX python API. We initialize the set of constraints based on the greedy heuristic.\nimport cplex prob = cplex.Cplex() numvar = len(G.nodes) def func(x): return \u0026quot;x\u0026quot;+str(x) names = list(map(func, G.nodes)) var_type = [prob.variables.type.continuous] * numvar prob.variables.add(names=names, lb=[0.0] * numvar, ub=[1.0] * numvar, types=var_type) prob.objective.set_sense(prob.objective.sense.maximize) prob.objective.set_linear([(n, 1.0) for n in names]) lhs = [] # Call the greedy heuristic to generate a starting set of independent sets mis = greedy_init(G) for iset in mis: con_vars = [func(i) for i in iset] coeffs = [1.0] * len(con_vars) lhs.append(cplex.SparsePair(con_vars, coeffs)) prob.linear_constraints.add(lin_expr=lhs, rhs=[1.0] * len(lhs), senses=['L'] * len(lhs)) print(\u0026quot;Constraint: Maximum independent set. ({} constraints)\u0026quot;.format(len(mis)))  To solve this model, we would use the following snippet to execute the model and return the final solution.\nprob.solve() status = prob.solution.status[prob.solution.get_status()] print(\u0026quot;Status:{}\u0026quot;.format(status)) if prob.solution.get_status() in [101, 105, 107, 111, 113]: # Optimal/feasible, so get the solution print(\u0026quot;Solution value: \u0026quot;) print(prob.solution.get_objective_value()) # get the configuration x_res = prob.solution.get_values(names) for x_name, val in zip(names, x_res): if val \u0026gt; 0: print(x_name, val)  (Step 3) Generate lazy constraints We\u0026rsquo;ve not managed the lazy constraints yet. To do this we will use a CPLEX Callback. The LazyConstraintCallback is called each time an optimal or integral solution is found. The implementation looks like this.\nTo find new independent sets, we take the solution (potentially fractional) and use a greedy heuristic to first generate an independent set on the induced subgraph of the solution. We then expand on the independent set for the entire graph using another greedy_expand procedure which uses the same logic as greedy_init to grown the independent set.\nIf there are no additional independent sets, no constraints are added and the solver terminates.\nclass LazyCallback(LazyConstraintCallback): \u0026quot;\u0026quot;\u0026quot;Lazy constraint callback to generate maximum independent sets on the fly. There are too many such constraints to make them all available to CPLEX right away - and in any case, very few of them are valid. So generate them on the fly. \u0026quot;\u0026quot;\u0026quot; # Callback constructor. # # Any needed fields are set externally after registering the callback. def __init__(self, env): super().__init__(env) def __call__(self): values = self.get_values(self.names) # Any node with non-zero value is considered as part of the set curr_solution = [int(name[1:]) for name, val in zip(self.names, values) if val \u0026gt;= 0.001] print(\u0026quot;Current solution: \u0026quot;, curr_solution) # Look to generate all independent sets that would cut off the (fractional) # value. To do this, first induce a subgraph - and for each node, built a # subG = self.G.subgraph(curr_solution) sub_ind_set = greedy_init(subG) max_ind_sets = [greedy_expand(self.G, sset) for sset in sub_ind_set] for iset in max_ind_sets: con_vars = [func(i) for i in iset] coeffs = [1.0] * len(con_vars) lhs = cplex.SparsePair(con_vars, coeffs) self.add(constraint=lhs, rhs=1.0, sense='L')  The callback must be registered with the problem instance and any variables passed as attributes as so:\nfrom cplex.callbacks import LazyConstraintCallback # register callbacks to generate additional independent sets on the fly lazycb = prob.register_callback(LazyCallback) # pass any arguments as class attributes lazycb.names = names lazycb.G = G  For completeness, here is what the greedy_expand function does\ndef greedy_expand(G, init_set): R = G.copy() neigh = [n for i in init_set for n in R.neighbors(i)] R.remove_nodes_from(init_set) R.remove_nodes_from(neigh) if R.number_of_nodes() != 0: x = get_min_degree_vertex(R) while R.number_of_nodes() != 0: neigh2 = [m for m in R.neighbors(x)] R.remove_node(x) init_set.append(x) R.remove_nodes_from(neigh2) if R.number_of_nodes() != 0: x = get_min_degree_vertex(R) return init_set  Putting it all together Running this all together as shown in this gist  gives the following output:\nConstraint: Maximum independent set. (18 constraints) Version identifier: 12.10.0.0 | 2019-11-26 | 843d4de CPXPARAM_Read_DataCheck 1 Warning: Control callbacks may disable some MIP features. Lazy constraint(s) or lazy constraint/branch callback is present. Disabling dual reductions (CPX_PARAM_REDUCE) in presolve. Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve. Disabling presolve reductions that prevent crushing forms. Disabling repeat represolve because of lazy constraint/incumbent callback. Tried aggregator 1 time. MIP Presolve eliminated 6 rows and 0 columns. Reduced MIP has 12 rows, 18 columns, and 72 nonzeros. Reduced MIP has 0 binaries, 0 generals, 0 SOSs, and 0 indicators. Presolve time = 0.00 sec. (0.02 ticks) MIP emphasis: balance optimality and feasibility. MIP search method: traditional branch-and-cut. Parallel mode: none, using 1 thread. Root relaxation solution time = 0.00 sec. (0.01 ticks) Current solution: [5, 7, 8, 14, 16, 17] Current solution: [4, 10, 11, 13] Current solution: [0, 6, 8, 10, 11] Current solution: [4, 6, 8, 10, 11, 16] Current solution: [0, 2, 4, 5, 6, 8] Current solution: [6, 7, 8] Current solution: [6, 7, 8] Nodes Cuts/ Node Left Objective IInf Best Integer Best Bound ItCnt Gap Variable B NodeID Parent Depth * 0 0 integral 0 3.0000 6.0000 8 100.00% 0 0 Elapsed time = 0.02 sec. (0.16 ticks, tree = 0.00 MB, solutions = 1) User cuts applied: 17 Root node processing (before b\u0026amp;c): Real time = 0.02 sec. (0.16 ticks) Sequential b\u0026amp;c: Real time = 0.00 sec. (0.00 ticks) ------------ Total (root+branch\u0026amp;cut) = 0.02 sec. (0.16 ticks) Status:MIP_optimal Solution value: 3.0 x6 1.0 x7 1.0 x8 1.0  This identified one of the 3-vertex cliques, which is the maximum. The program started with 18 maximum independent sets generated greedily. It generated a further 17 user cuts one for each new independent set that were constructed on the fly. For a graph with $n$ nodes, there can be at most $3^{n/3}$ maximum independent sets although most have far fewer. For our 18 node graph, that would be 729 sets. In this greedy solution method, we got away with generating just 35.\n","date":1591350299,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593011846,"objectID":"84e62885cc885b92f01c70331bc9342a","permalink":"https://rahulnair23.github.io/post/max-clique/","publishdate":"2020-06-05T10:44:59+01:00","relpermalink":"/post/max-clique/","section":"post","summary":"Recently, I had the need to compute maximum weighted cliques on very dense large graphs. This is a well studied problem, and a nice survey paper from 90\u0026rsquo;s by Pardalos and Xue gives a good overview of approaches.","tags":["optimization","graph theory","lazy constraints"],"title":"Maximum weighted cliques in a graph","type":"post"},{"authors":["Sergiy Zhuk","Jonathan P Epperlein","Rahul Nair","Seshu Thirupati","Pol Mac Aonghusa","Ronan Cahill","Donal O'Shea"],"categories":[],"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"53f64aa71ad2e41d1d5e742bf18dc62b","permalink":"https://rahulnair23.github.io/publication/zhuk-2020-perfusion/","publishdate":"2020-08-21T09:43:13.374296Z","relpermalink":"/publication/zhuk-2020-perfusion/","section":"publication","summary":"Describes methods for interoperative decision support during endoscopies.","tags":["cancer","video","classification"],"title":"Perfusion Quantification from Endoscopic Videos: Learning to Read Tumor Signatures","type":"publication"},{"authors":["Josh Andres","Christine T Wolf","Sergio Cabrero Barros","Erick Oduor","Rahul Nair","Alexander Kjærum","Anders Bech Tharsgaard","Bo Schwartz Madsen"],"categories":[],"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"9543d9645ed7e8b003481809d9388856","permalink":"https://rahulnair23.github.io/publication/andres-2020-scenario/","publishdate":"2020-08-21T09:43:13.279135Z","relpermalink":"/publication/andres-2020-scenario/","section":"publication","summary":"One domain application of artificial intelligence (AI) systems is humanitarian aid planning, where dynamically changing societal conditions need to be monitored and analyzed, so humanitarian organizations can coordinate efforts and appropriately support forcibly displaced peoples. Essential in facilitating effective human-AI collaboration is the explainability of AI system outputs (XAI). This late-breaking work presents an ongoing industrial research project aimed at designing, building, and implementing an XAI system for humanitarian aid planning. We draw on empirical data from our project and define current and future scenarios of use, adopting a scenario-based XAI design approach. These scenarios surface three central themes which shape human-AI collaboration in humanitarian aid planning: (1) Surfacing Causality, (2) Multifaceted Trust \u0026 Lack of Data Quality, (3) Balancing Risky Situations. We explore each theme and in doing so, further our understanding of how humanitarian aid planners can partner with AI systems to better support forcibly displaced peoples.","tags":["HCI","displacement","explainability"],"title":"Scenario-based XAI for Humanitarian Aid Forecasting","type":"publication"},{"authors":["Rahul Nair","Anton Dekusar"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"6007213cc15d6bce7f8fd0a98ffb76b3","permalink":"https://rahulnair23.github.io/publication/nair-2020-keep/","publishdate":"2020-08-21T09:43:13.085705Z","relpermalink":"/publication/nair-2020-keep/","section":"publication","summary":"The approach taken by the second place winner of the TRANSFOR prediction challenge is presented. The challenge involves forecasting travel speeds on two arterial links in Xi’an City in China for two five hour periods on a single day. Travel speeds are measured from trajectory information on probe vehicles from a fleet of vehicles for a large sub-area of the city. After experimenting with several deep learning methods, we settle on a simple non-parametric kernel regression approach. The method, borrowed from previous work in fixed route transit predictions, formalizes the intuition that in urban systems most failure patterns are recurrent. Our choice is supported by test results where the method outperformed all evaluated neural architectures. The results suggest simple methods are very competitive, particularly considering the high lifecycle cost of deep learning models.","tags":[],"title":"Keep it simple stupid! A non-parametric kernel regression approach to forecast travel speeds","type":"publication"},{"authors":["Bei Chen","Rahul Nair","Inge Vejsbjerg"],"categories":[],"content":"","date":1573171200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"04edaf0bd639a54c4ba8f26d83d81d31","permalink":"https://rahulnair23.github.io/publication/chen-2019-rsm/","publishdate":"2020-08-21T09:43:13.183611Z","relpermalink":"/publication/chen-2019-rsm/","section":"publication","summary":"We present Route Selection Model (RSM), an online data-driven sales route selector to help firms decide on how to respond to new business opportunities. The system addresses sales route selection (also known as sales channel selection) to determine if the opportunity can be handled by business partners, within the firm using sales agents on the field, or aim to close remotely using digital sellers. Given a new opportunity, RSM recommends an optimal sales route with the highest win probability predicted by machine learning models and provides explanation by meaningful clauses. Compared to the traditional manual passing approach based on business rules, RSM makes faster and more objective recommendations. Our pilot evaluation study shows our recommendations are not only accurate but also interpretable, which is crucial in business decision making. The main features of RSM are: (1) automatically merges multiple sales databases and produce timely recommendations, (2) allows users to navigate through the opportunity information and evidence which supports the recommendation. In this paper we describe the methodology and demonstrate the main functions of RSM.","tags":[],"title":"RSM: An Explainable Predictive Sales Route Selector","type":"publication"},{"authors":["Rahul Nair","Bo Schwartz Madsen","Helena Lassen","Serge Baduk","Srividya Nagarajan","Lars Henrik Mogensen","Rana Novack","Rebecca Curzon","Jurij Paraszczak","Sanne Urbak"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"c1d8194bfc5fd4b1562f32f0ff704b29","permalink":"https://rahulnair23.github.io/publication/nair-2019-machine/","publishdate":"2020-08-21T09:43:12.987186Z","relpermalink":"/publication/nair-2019-machine/","section":"publication","summary":"The development of MM4SIGHT, a machine learning system that enables annual forecasts of mixed-migration flows, is presented. Mixed migration refers to cross-border movements of people that are motivated by a multiplicity of factors to move including refugees fleeing persecution and conflict, victims of trafficking, and people seeking better lives and opportunity. Such populations have a range of legal status, some of which are not reflected in official government statistics. The system combines institutional estimates of migration along with in-person monitoring surveys to establish a migration volume baseline. The surveys reveal clusters of migratory drivers of populations on the move. Given macrolevel indicators that reflect migratory drivers found in the surveys, we develop an ensemble model to determine the volume of migration between source and host country along with uncertainty bounds. Using more than 80 macroindicators, we present results from a case study of migratory flows from Ethiopia to six countries. Our evaluations show error rates for annual forecasts to be within a few thousand persons per year for most destinations.","tags":[],"title":"A machine learning approach to scenario analysis and forecasting of mixed migration","type":"publication"},{"authors":["Rahul Nair","Thanh Lam Hoang","Marco Laumanns","Bei Chen","Randall Cogill","Jácint Szabó","Thomas Walter"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"3d70b5ede1c1be85fdf3b684f1040618","permalink":"https://rahulnair23.github.io/publication/nair-2019-ensemble/","publishdate":"2020-08-21T09:43:12.711624Z","relpermalink":"/publication/nair-2019-ensemble/","section":"publication","summary":"A large-scale ensemble prediction model to predict train delays is presented. The ensemble model uses a disparate set of models, two statistical and one simulation-based to generate forecasts of train delays. The first statistical model is a context-aware random forest that accounts for network traffic states, such as likely stretch conflicts and current headway’s, exogenous weather, event, and work zone information. The second model is a kernel regression that captures train-specific dynamics. A mesoscopic simulation model that accounts for travel and dwell time variations as well as inferred track occupation conflicts, train connections and rolling stock rotations, is additionally considered. The models have been used in a proof of concept to forecast delays for nationwide passenger services network of Deutsche Bahn, which operates roughly 25,000 trains daily in Germany. Results demonstrate a 25% improvement potential in forecast correctness (fraction of predictions within one minute) and 50% reduction in root mean squared errors compared to the published schedule. The paper describes the models along with the big data challenges that were addressed in data storage, feature and model building, and computation.","tags":[],"title":"An ensemble prediction model for train delays","type":"publication"},{"authors":["Rahul Nair","Killian Levacher","Martin Stephenson"],"categories":[],"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"52293dff77f54c4c5dc617b8791df212","permalink":"https://rahulnair23.github.io/publication/nair-2018-towards/","publishdate":"2020-08-21T09:43:13.578702Z","relpermalink":"/publication/nair-2018-towards/","section":"publication","summary":"","tags":[],"title":"Towards Automated Extraction of Business Constraints from Unstructured Regulatory Text","type":"publication"},{"authors":["Matthias Andres","Rahul Nair"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"f988865b25d479174032288741a2765a","permalink":"https://rahulnair23.github.io/publication/andres-2017-predictive/","publishdate":"2020-08-21T09:43:13.677413Z","relpermalink":"/publication/andres-2017-predictive/","section":"publication","summary":"","tags":[],"title":"A predictive-control framework to address bus bunching","type":"publication"},{"authors":["Ren Wang","Rahul Nair","Alessandra Pascale","Daniel Work"],"categories":[],"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"8813329b5724497bcb93c091241fba4b","permalink":"https://rahulnair23.github.io/publication/wang-2016-spillover/","publishdate":"2020-08-21T09:43:13.774054Z","relpermalink":"/publication/wang-2016-spillover/","section":"publication","summary":"","tags":[],"title":"Spillover detection for urban traffic networks using signal timing and stop line detector data","type":"publication"},{"authors":["Mohammed Ahmed","Gianni Barlacchi","Stefano Braghin","Francesco Calabrese","Michele Ferretti","Vincent Lonij","Rahul Nair","Rana Novack","Jurij Paraszczak","Andeep Toor"],"categories":[],"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"cd6edc7244a11f9e6783def9028f6946","permalink":"https://rahulnair23.github.io/publication/mohammed-2016-multiscale/","publishdate":"2020-08-21T09:43:14.161802Z","relpermalink":"/publication/mohammed-2016-multiscale/","section":"publication","summary":"","tags":[],"title":" A multi-scale approach to data-driven mass migration analysis","type":"publication"},{"authors":["Giusy Di Lorenzo","Marco Sbodio","Francesco Calabrese","Michele Berlingerio","Fabio Pinelli","Rahul Nair"],"categories":[],"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"e282719be601a09440e73f43cbd319e1","permalink":"https://rahulnair23.github.io/publication/di-2016-allaboard/","publishdate":"2020-08-21T09:43:13.869369Z","relpermalink":"/publication/di-2016-allaboard/","section":"publication","summary":"","tags":[],"title":"Allaboard: visual exploration of cellphone mobility data to optimise public transport","type":"publication"},{"authors":["Fabio Pinelli","Rahul Nair","Francesco Calabrese","Michele Berlingerio","G. Di Lorenzo","Marco Luca Sbodio"],"categories":[],"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"4046c3ca4f54986d2b7f924731d76a92","permalink":"https://rahulnair23.github.io/publication/pinelli-2016-data/","publishdate":"2020-08-21T09:43:13.476739Z","relpermalink":"/publication/pinelli-2016-data/","section":"publication","summary":"","tags":[],"title":"Data-Driven Transit Network Design From Mobile Phone Trajectories","type":"publication"},{"authors":["A. Botea","M. Berlingerio","S. Braghin","E. Bouillet","F. Calabrese","B. Chen","Y. Gkoufas","R. Nair"," Nonner","Laumanns, M T."],"categories":[],"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"187e11dd1fab8a4d7d76dea7eb0309fc","permalink":"https://rahulnair23.github.io/publication/botea-2016-docit/","publishdate":"2020-08-21T09:43:13.966295Z","relpermalink":"/publication/botea-2016-docit/","section":"publication","summary":"","tags":[],"title":"Docit: an integrated system for risk-averse multimodal journey advising","type":"publication"},{"authors":["A. Pascale","T.L. Hoang","R. Nair"],"categories":[],"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"f63ca965fbf84089666d41268b902ab6","permalink":"https://rahulnair23.github.io/publication/pascale-2015-isttt/","publishdate":"2020-08-21T09:43:16.013874Z","relpermalink":"/publication/pascale-2015-isttt/","section":"publication","summary":"","tags":[],"title":"Characterization of network traffic processes under adaptive traffic control systems","type":"publication"},{"authors":["A. Pascale","T.L. Hoang","R. Nair"],"categories":[],"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"ea24d734b59299c34908f66d404e4245","permalink":"https://rahulnair23.github.io/publication/pascale-2015-trc/","publishdate":"2020-08-21T09:43:15.91899Z","relpermalink":"/publication/pascale-2015-trc/","section":"publication","summary":"","tags":[],"title":"Characterization of network traffic processes under adaptive traffic control systems","type":"publication"},{"authors":["Nikola Marković","Rahul Nair","Paul Schonfeld","Elise Miller-Hooks","Matthew Mohebbi"],"categories":[],"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"e2a70e7b878cc614a9168cb2dffbec62","permalink":"https://rahulnair23.github.io/publication/markovic-2015-optimizing/","publishdate":"2020-08-21T09:43:14.753238Z","relpermalink":"/publication/markovic-2015-optimizing/","section":"publication","summary":"","tags":[],"title":"Optimizing dial-a-ride services in Maryland: Benefits of computerized routing and scheduling","type":"publication"},{"authors":["Marco Luca Sbodio","Francesco Calabrese","Michele Berlingerio","Rahul Nair","Fabio Pinelli"," others"],"categories":[],"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"18336311478d85a12304ed1a1f8d994c","permalink":"https://rahulnair23.github.io/publication/sbodio-2014-allaboard/","publishdate":"2020-08-21T09:43:14.853057Z","relpermalink":"/publication/sbodio-2014-allaboard/","section":"publication","summary":"","tags":[],"title":"Allaboard: visual exploration of cellphone mobility data to optimise public transport","type":"publication"},{"authors":["Rahul Nair","Eric Bouillet","Yiannis Gkoufas","Olivier Verscheure","Magda Mourad","Farzin Yashar","Rosie Perez","Joel Perez","Gerald Bryant"],"categories":[],"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"c6d6832d132458af246cb83b7c8c2651","permalink":"https://rahulnair23.github.io/publication/nair-2015-data/","publishdate":"2020-08-21T09:43:14.957703Z","relpermalink":"/publication/nair-2015-data/","section":"publication","summary":"","tags":[],"title":"Data as a resource: real-time predictive analytics for bus bunching","type":"publication"},{"authors":["Rahul Nair","Elise Miller-Hooks"],"categories":[],"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"80de2c668c7bfceb4cbe110db2365449","permalink":"https://rahulnair23.github.io/publication/nair-2014-equ-dc/","publishdate":"2020-08-21T09:43:16.303221Z","relpermalink":"/publication/nair-2014-equ-dc/","section":"publication","summary":"","tags":["\"Equilibrium network design; Bike sharing; Transit accessibility\""],"title":"Equilibrium design of bicycle sharing systems: the case of Washington D.C.","type":"publication"},{"authors":["Rahul Nair","Elise Miller-Hooks"],"categories":[],"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"a6c8d336ad7b6007c6c683638eb93437","permalink":"https://rahulnair23.github.io/publication/nair-2014-equilibrium/","publishdate":"2020-08-21T09:43:14.564359Z","relpermalink":"/publication/nair-2014-equilibrium/","section":"publication","summary":"","tags":[],"title":"Equilibrium network design of shared-vehicle systems","type":"publication"},{"authors":["Freddy Lécué","Robert Tucker","Simone Tallevi-Diotallevi","Rahul Nair","Yiannis Gkoufas","Giuseppe Liguori","Mauro Borioni","Alexandre Rademaker","Luciano Barbosa"],"categories":[],"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"1c284d04d33a4b0d611bc230d605e813","permalink":"https://rahulnair23.github.io/publication/lecue-2014-semantic/","publishdate":"2020-08-21T09:43:14.656302Z","relpermalink":"/publication/lecue-2014-semantic/","section":"publication","summary":"","tags":[],"title":"Semantic Traffic Diagnosis with STAR-CITY: Architecture and Lessons Learned from Deployment in Dublin, Bologna, Miami and Rio","type":"publication"},{"authors":["Michele Berlingerio","Francesco Calabrese","Giusy Di Lorenzo","Rahul Nair","Fabio Pinelli","Marco Luca Sbodio"],"categories":[],"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"def95f16d7b73e407a11c2b04ea88c5b","permalink":"https://rahulnair23.github.io/publication/berlingerio-2013-allaboard/","publishdate":"2020-08-21T09:43:14.06083Z","relpermalink":"/publication/berlingerio-2013-allaboard/","section":"publication","summary":"","tags":[],"title":"AllAboard: a system for exploring urban mobility and optimizing public transport using cellphone data","type":"publication"},{"authors":["Rahul Nair","Cathal Coffey","Fabio Pinelli","Francesco Calabrese"],"categories":[],"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"f5b5c8cd1a7c350110e65ed0360f73e9","permalink":"https://rahulnair23.github.io/publication/nair-2013-trb/","publishdate":"2020-08-21T09:43:14.469943Z","relpermalink":"/publication/nair-2013-trb/","section":"publication","summary":"","tags":[],"title":"Large-scale transit schedule coordination based on journey planner requests","type":"publication"},{"authors":["Rahul Nair","Jonathan Kumi","Kevin Denny","Elise Miller-Hooks"],"categories":[],"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"bf455a7208c4adc9ce614f3ea7625aa4","permalink":"https://rahulnair23.github.io/publication/nair-2013-robust/","publishdate":"2020-08-21T09:43:16.881239Z","relpermalink":"/publication/nair-2013-robust/","section":"publication","summary":"","tags":[],"title":"Robust Dynamic Distribution of Security Assets in Transit Systems","type":"publication"},{"authors":["Center for Advanced Transportation Technology"],"categories":[],"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"e7d167a1ae0c7a70d21e8858b77b8ff0","permalink":"https://rahulnair23.github.io/publication/sh-amobilityreport/","publishdate":"2020-08-21T09:43:15.054525Z","relpermalink":"/publication/sh-amobilityreport/","section":"publication","summary":"","tags":[],"title":"2012 Maryland State Highway Mobility Report","type":"publication"},{"authors":["R. Nair","H.S. Mahmassani","E. Miller-Hooks"],"categories":[],"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"c5d4591bc4ccfaf683c219dbe7df7068","permalink":"https://rahulnair23.github.io/publication/nair-2012-porous/","publishdate":"2020-08-21T09:43:16.781385Z","relpermalink":"/publication/nair-2012-porous/","section":"publication","summary":"","tags":[],"title":"A Porous Flow Model for Disordered Heterogeneous Traffic Streams","type":"publication"},{"authors":["R. Nair","E. Miller-Hooks","R. C. Hampshire","A. Bušić"],"categories":[],"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"7d3c47c66bdd7e06cabf505a4a73477d","permalink":"https://rahulnair23.github.io/publication/nair-2012-large/","publishdate":"2020-08-21T09:43:16.107379Z","relpermalink":"/publication/nair-2012-large/","section":"publication","summary":"","tags":[],"title":"Large-Scale Vehicle Sharing Systems: Analysis of Vélib'","type":"publication"},{"authors":["Cathal Coffey","Rahul Nair","Fabio Pinelli","Alexei Pozdnoukhov","Francesco Calabrese"],"categories":[],"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"ac655916e056f8f0fdf87b28449e134f","permalink":"https://rahulnair23.github.io/publication/coffey-2012-missed/","publishdate":"2020-08-21T09:43:14.276249Z","relpermalink":"/publication/coffey-2012-missed/","section":"publication","summary":"","tags":[],"title":"Missed connections: quantifying and optimizing multi-modal interconnectivity in cities","type":"publication"},{"authors":["H. Sadrsadat","S. Young","E. Sharifi","R. Nair"],"categories":[],"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"3eefb7d25c3ef247022eb4afd75c358b","permalink":"https://rahulnair23.github.io/publication/sadrsadat-2012-relation/","publishdate":"2020-08-21T09:43:16.983549Z","relpermalink":"/publication/sadrsadat-2012-relation/","section":"publication","summary":"","tags":[],"title":"Relation between Real-Time Data and Hourly Traffic Volume Taking Heavy Vehicles into Consideration","type":"publication"},{"authors":["M. Kim","E. Miller-Hooks","R. Nair"],"categories":[],"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"fdc1e0631e2daf63068fc54422e9b6f2","permalink":"https://rahulnair23.github.io/publication/kim-2011-geographic/","publishdate":"2020-08-21T09:43:16.403063Z","relpermalink":"/publication/kim-2011-geographic/","section":"publication","summary":"","tags":[],"title":"A Geographic Information System-Based Real-Time Decision Support Framework for Routing Vehicles Carrying Hazardous Materials","type":"publication"},{"authors":["R. Nair","H.S. Mahmassani","E. Miller-Hooks"],"categories":[],"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"0d3dde0b671aaa4defc3de962d5bb92f","permalink":"https://rahulnair23.github.io/publication/nair-2011-isttt/","publishdate":"2020-08-21T09:43:15.825073Z","relpermalink":"/publication/nair-2011-isttt/","section":"publication","summary":"","tags":[],"title":"A porous flow approach to modeling heterogeneous traffic in disordered systems","type":"publication"},{"authors":["Rahul Nair","Hani S Mahmassani","Elise Miller-Hooks"],"categories":[],"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"1281930376066565320c64eeade8f0c9","permalink":"https://rahulnair23.github.io/publication/nair-2011-porous/","publishdate":"2020-08-21T09:43:15.729844Z","relpermalink":"/publication/nair-2011-porous/","section":"publication","summary":"","tags":[],"title":"A porous flow approach to modeling heterogeneous traffic in disordered systems","type":"publication"},{"authors":["R. Nair","E. Miller-Hooks"],"categories":[],"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"ba44ba264ed5e1cdcdf9c381fd59bf65","permalink":"https://rahulnair23.github.io/publication/nair-2011-fleet/","publishdate":"2020-08-21T09:43:15.534537Z","relpermalink":"/publication/nair-2011-fleet/","section":"publication","summary":"","tags":[],"title":"Fleet management for vehicle sharing operations","type":"publication"},{"authors":["R. Nair"],"categories":[],"content":"","date":1262304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"7f962f0ee904b663738067ede3725761","permalink":"https://rahulnair23.github.io/publication/nair-2010-design/","publishdate":"2020-08-21T09:43:16.685419Z","relpermalink":"/publication/nair-2010-design/","section":"publication","summary":"","tags":[],"title":"Design and Analysis of Vehicle Sharing Programs: A Systems Approach","type":"publication"},{"authors":["R. Nair","H. Avetisyan","E. Miller-Hooks"],"categories":[],"content":"","date":1262304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"1b8451c824cc27d568d3124b23df981f","permalink":"https://rahulnair23.github.io/publication/nair-2010-resilience/","publishdate":"2020-08-21T09:43:16.591617Z","relpermalink":"/publication/nair-2010-resilience/","section":"publication","summary":"","tags":[],"title":"Resilience Framework for Ports and Other Intermodal Components","type":"publication"},{"authors":["R. Nair","E. Miller-Hooks"],"categories":[],"content":"","date":1230768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"decf075a2f573c3ec49bd136a3db40dc","permalink":"https://rahulnair23.github.io/publication/nair-2009-evaluation/","publishdate":"2020-08-21T09:43:15.24628Z","relpermalink":"/publication/nair-2009-evaluation/","section":"publication","summary":"","tags":[],"title":"Evaluation of relocation strategies for emergency medical service vehicles","type":"publication"},{"authors":["E. Miller-Hooks","L.L. Chen","R. Nair","H.S. Mahmassani"],"categories":[],"content":"","date":1230768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"f7827ea16d1763c13cae0c4e63fc8fab","permalink":"https://rahulnair23.github.io/publication/miller-2009-security/","publishdate":"2020-08-21T09:43:16.206041Z","relpermalink":"/publication/miller-2009-security/","section":"publication","summary":"","tags":[],"title":"Security and Mobility of Intermodal Freight Networks","type":"publication"},{"authors":["K. Zhang","R. Nair","H.S. Mahmassani","E.D. Miller-Hooks","V.C. Arcot","A. Kuo","J. Dong","C.C. Lu"],"categories":[],"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"f80952cf5a3bb599d44eaf639a1649a0","permalink":"https://rahulnair23.github.io/publication/zhang-2008-application/","publishdate":"2020-08-21T09:43:15.33964Z","relpermalink":"/publication/zhang-2008-application/","section":"publication","summary":"","tags":[],"title":"Application and Validation of Dynamic Freight Simulation-Assignment Model to Large-Scale Intermodal Rail Network: Pan-European Case","type":"publication"},{"authors":["R. Nair","E. Miller-Hooks"],"categories":[],"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"f7419abff3eb7ea6555be8dba98b90ac","permalink":"https://rahulnair23.github.io/publication/nair-2008-dynamic/","publishdate":"2020-08-21T09:43:16.498918Z","relpermalink":"/publication/nair-2008-dynamic/","section":"publication","summary":"","tags":[],"title":"Dynamic Relocation of Scarce Resources: The Case of Emergency Medical Service Vehicles in Montreal","type":"publication"},{"authors":["R. Nair","E.D. Miller-Hooks","H.S. Mahmassani","V.C. Arcot","A. Kuo","K. Zhang","A. Kozuki","J. Ludvigsen"],"categories":[],"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"fa73b36a50a7b7bd2e2801beed0c9ff8","permalink":"https://rahulnair23.github.io/publication/nair-2008-market/","publishdate":"2020-08-21T09:43:15.436508Z","relpermalink":"/publication/nair-2008-market/","section":"publication","summary":"","tags":[],"title":"Market potential for international rail-based intermodal services in Europe: From sea to shining sea","type":"publication"},{"authors":["E. Miller-Hooks","H.S. Mahmassani","R. Nair","K. Zhang","V.C. Arcot","A. Kuo","C.C. Lu","J. Dong","A. Kozuki","A. Consult"],"categories":[],"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"e87aba2a1cd350adda5d2c728fe4eb5b","permalink":"https://rahulnair23.github.io/publication/miller-2007-assessing/","publishdate":"2020-08-21T09:43:15.631765Z","relpermalink":"/publication/miller-2007-assessing/","section":"publication","summary":"","tags":[],"title":"Assessing Service Design Options and Strategies for Overcoming Barriers in the Reorient Intermodal Freight Transport Corridor","type":"publication"},{"authors":["VC Arcot","A. Caprara","C. D'Ambrosio","J. Dong","A. Kozuki","A. Kuo","CC Lu","H. Mahmassani","E. Malaguti","S. Martello"," others"],"categories":[],"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"39378600e79b37b6a1eeaee5fcac70da","permalink":"https://rahulnair23.github.io/publication/arcot-2007-modelling/","publishdate":"2020-08-21T09:43:15.149716Z","relpermalink":"/publication/arcot-2007-modelling/","section":"publication","summary":"","tags":[],"title":"Modelling corridor freight transport for demonstration of seamless international rail freight services","type":"publication"},{"authors":["R. Nair","W. Ressel","R. Sivanandan"],"categories":[],"content":"","date":1072915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598006701,"objectID":"be6f1b1ca79cc8836028c3ac224a1263","permalink":"https://rahulnair23.github.io/publication/nair-2004/","publishdate":"2020-08-21T09:43:14.37459Z","relpermalink":"/publication/nair-2004/","section":"publication","summary":"","tags":[],"title":"Application of floating car data using GIS for dynamic vehicular routing: A case study","type":"publication"}]