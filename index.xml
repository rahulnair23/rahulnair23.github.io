<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Rahul Nair</title>
    <link>https://rahulnair23.github.io/</link>
      <atom:link href="https://rahulnair23.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>Rahul Nair</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 05 Jun 2020 10:44:59 +0100</lastBuildDate>
    <image>
      <url>https://rahulnair23.github.io/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Rahul Nair</title>
      <link>https://rahulnair23.github.io/</link>
    </image>
    
    <item>
      <title>Maximum weighted cliques in a graph</title>
      <link>https://rahulnair23.github.io/post/max-clique/</link>
      <pubDate>Fri, 05 Jun 2020 10:44:59 +0100</pubDate>
      <guid>https://rahulnair23.github.io/post/max-clique/</guid>
      <description>&lt;p&gt;Recently, I had the need to compute maximum weighted cliques on very dense large graphs. This is a well studied problem, and a nice 
&lt;a href=&#34;https://doi.org/10.1007/BF01098364&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;survey paper&lt;/a&gt; from 90&amp;rsquo;s by Pardalos and Xue gives a good overview of approaches.&lt;/p&gt;
&lt;h2 id=&#34;the-problem&#34;&gt;The problem&lt;/h2&gt;
&lt;p&gt;We are given a graph $G = (V, E)$ which is a set of vertices $V$ and edges $E$. Each vertex has an associated weight $d_i, \forall i\in V$. A &lt;em&gt;clique&lt;/em&gt; $C$ is a subset of vertices, where all vertices are pairwise connected. A &lt;em&gt;maximum&lt;/em&gt; clique is a clique that has largest weight.&lt;/p&gt;
&lt;p&gt;A related notion is of an &lt;em&gt;independent set&lt;/em&gt;, which is a subset of vertices $V$ that are pairwise disconnected. A maximum independent set is similarly an independent set with the largest weight.&lt;/p&gt;
&lt;h2 id=&#34;solutions&#34;&gt;Solutions&lt;/h2&gt;
&lt;p&gt;For general graphs, finding the maximum cliques is a hard problem (NP-complete). An integer programming approach that involves edges can be written as:&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\max_x &amp;amp; \sum_{i\in V} d_i x_{i}\\&lt;br&gt;
\mbox{s.t.} \qquad &amp;amp; x_i + x_j \le 1 \quad \forall (i, j) \in \bar{E} \\&lt;br&gt;
&amp;amp; x_i \in {0, 1} \qquad \forall i\in V
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;where $\bar{E}$ is called the complement edge set that is a set of edges that are missing from the original graph $G$. All the constraint $x_i + x_j \le 1$ says is if the edge $(i, j)$ is missing then only one node, either $i$ or $j$, can be in the clique. The objective seeks to maximize the weighted of selected nodes.&lt;/p&gt;
&lt;p&gt;As pointed out in the 
&lt;a href=&#34;https://doi.org/10.1007/BF01098364&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;paper&lt;/a&gt; this formulation isn&amp;rsquo;t useful in practice on account of two problems. First, the linear relaxation, one where the integrality constraints $x_i \in {0, 1}$ is omitted, gives a poor bound. The second is on account of symmetry. Symmetry arises in this context as vertices with the same weight are indistinguishable. So several configurations result in the same optimal solution. Why is this bad? The branch and cut tree cannot prune the search tree as solutions are in various parts of it. One way to remove symmetry is to do lexicographical ordering. An arbitrary order is imposed via additional constraints that cuts of several optimal solutions knowing that at least one optimal solution is valid. There are other methods as well, such as 
&lt;a href=&#34;https://doi.org/10.1007/s10107-002-0358-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;isomorphic pruning&lt;/a&gt;, and 
&lt;a href=&#34;https://doi.org/10.1016/j.disopt.2011.07.001&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;orbitopal fixing&lt;/a&gt;,&lt;/p&gt;
&lt;h2 id=&#34;an-alternative-formulation&#34;&gt;An alternative formulation&lt;/h2&gt;
&lt;p&gt;The notion of the complement edge set $\bar{E}$ can be strengthened using independent sets. If you know an independent set, a clique can contain at most one vertex from such a set. To write this as a constraint, one would need to consider &lt;em&gt;maximum&lt;/em&gt; independent sets, lest you allow the omitted vertices to be included in the clique. Further, you would need to look at all maximum independent sets that arise in $G$. Assume for a moment that the set of maximum independent sets $\mathbb{S}$ is known. Then the problem of finding the maximum weighted clique can be written as&lt;/p&gt;
&lt;p&gt;$$\begin{aligned}
\max_x &amp;amp; \sum_{i\in V} d_i x_{i}\\&lt;br&gt;
\mbox{s.t.} \qquad &amp;amp; \sum_{i\in I} x_i \le 1 \quad \forall I \in \mathbb{S} \\&lt;br&gt;
&amp;amp; x_i \in {0, 1} \qquad \forall i\in V
\end{aligned}
$$&lt;/p&gt;
&lt;p&gt;The objective is the same as before - maximize the total weight of selected nodes. The constraints, one for each maximum independent set, allows only one vertex into the solution. The constraints are tighter than the previous formulation implying that the linear relaxation gives a better bound. For some classes of graphs, namely perfect graphs, omitting the integrality constraints will directly give you integral solutions! The problem however is that there are now an exponential number of constraints (set $\mathbb{S}$ is very large).&lt;/p&gt;
&lt;p&gt;One mechanism to deal with too many constraints is use lazy constraints. The idea is to start the optimization with a small set of constraints and then add &lt;em&gt;relevant&lt;/em&gt; constraints from the large pool as you go along. The prerequisite is however that such relevant constraints can be generated efficiently.&lt;/p&gt;
&lt;p&gt;How would this work? A sketch of the solution algorithm looks like this.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use a heuristic procedure to generate a set of maximum independent sets ($S$)&lt;/li&gt;
&lt;li&gt;Solve a linear relaxation on this limited set ($S \subseteq \mathbb{S}$)&lt;/li&gt;
&lt;li&gt;Based on solution, identify new maximum independent sets that would cut the current solution&lt;/li&gt;
&lt;li&gt;If no such sets exists, we are done (current solution gives the maximum weighted clique)&lt;/li&gt;
&lt;li&gt;If there are, then add to the constraints and goto step 2.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;reference-implementation&#34;&gt;Reference implementation&lt;/h2&gt;
&lt;p&gt;To test this, we use the &lt;code&gt;networkx&lt;/code&gt; library for graphs and the CPLEX solver. We use one of the many generators for a test graph with a known number of cliques.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from networkx import nx
G = nx.generators.ring_of_cliques(6, 3)
nx.draw(G, with_labels=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;gives you this:&lt;/p&gt;





  
  











&lt;figure id=&#34;figure-an-test-graph-with-known-max-cliques&#34;&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;https://rahulnair23.github.io/post/max-clique/graph_hu66fa372f34c55a7f200bf8e44ac04457_35825_2000x2000_fit_lanczos_2.png&#34; data-caption=&#34;An test graph with known max cliques&#34;&gt;


  &lt;img data-src=&#34;https://rahulnair23.github.io/post/max-clique/graph_hu66fa372f34c55a7f200bf8e44ac04457_35825_2000x2000_fit_lanczos_2.png&#34; class=&#34;lazyload&#34; alt=&#34;&#34; width=&#34;640&#34; height=&#34;480&#34;&gt;
&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    An test graph with known max cliques
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h4 id=&#34;step-1-generating-maximum-independent-sets&#34;&gt;(Step 1) Generating maximum independent sets&lt;/h4&gt;
&lt;p&gt;Here we use the greedy heuristic implementation as shown in this 
&lt;a href=&#34;https://kmutya.github.io/maxclique/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;blog&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def greedy_init(G):
    &amp;quot;&amp;quot;&amp;quot;
    https://kmutya.github.io/maxclique/
    &amp;quot;&amp;quot;&amp;quot;
    n = G.number_of_nodes()  # Storing total number of nodes in &#39;n&#39;
    max_ind_sets = []  # initializing a list that will store maximum independent sets
    for j in G.nodes:
        R = G.copy()  # Storing a copy of the graph as a residual
        neigh = [n for n in R.neighbors(j)]  # Catch all the neighbours of j
        R.remove_node(j)  # removing the node we start from
        iset = [j]
        R.remove_nodes_from(neigh)  # Removing the neighbours of j
        if R.number_of_nodes() != 0:
            x = get_min_degree_vertex(R)
        while R.number_of_nodes() != 0:
            neigh2 = [m for m in R.neighbors(x)]
            R.remove_node(x)
            iset.append(x)
            R.remove_nodes_from(neigh2)
            if R.number_of_nodes() != 0:
                x = get_min_degree_vertex(R)

        max_ind_sets.append(iset)

    return(max_ind_sets)


def get_min_degree_vertex(Residual_graph):
    &#39;&#39;&#39;Takes in the residual graph R and returns the node with the lowest degree&#39;&#39;&#39;
    degrees = [val for (node, val) in Residual_graph.degree()]
    node = [node for (node, val) in Residual_graph.degree()]
    node_degree = dict(zip(node, degrees))
    return (min(node_degree, key=node_degree.get))
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-2-the-optimization-model&#34;&gt;(Step 2) The optimization model&lt;/h4&gt;
&lt;p&gt;Now we define the optimization model as a linear program using the CPLEX python API. We initialize the set of constraints based on the greedy heuristic.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import cplex

prob = cplex.Cplex()
numvar = len(G.nodes)

def func(x): return &amp;quot;x&amp;quot;+str(x)

names = list(map(func, G.nodes))
var_type = [prob.variables.type.continuous] * numvar
prob.variables.add(names=names,
                   lb=[0.0] * numvar,
                   ub=[1.0] * numvar,
                   types=var_type)
prob.objective.set_sense(prob.objective.sense.maximize)
prob.objective.set_linear([(n, 1.0) for n in names])
lhs = []

# Call the greedy heuristic to generate a starting set of independent sets
mis = greedy_init(G)

for iset in mis:
    con_vars = [func(i) for i in iset]
    coeffs = [1.0] * len(con_vars)
    lhs.append(cplex.SparsePair(con_vars, coeffs))
prob.linear_constraints.add(lin_expr=lhs,
                            rhs=[1.0] * len(lhs),
                            senses=[&#39;L&#39;] * len(lhs))
print(&amp;quot;Constraint: Maximum independent set. ({} constraints)&amp;quot;.format(len(mis)))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To solve this model, we would use the following snippet to execute the model and return the final solution.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;prob.solve()
status = prob.solution.status[prob.solution.get_status()]
print(&amp;quot;Status:{}&amp;quot;.format(status))

if prob.solution.get_status() in [101, 105, 107, 111, 113]:
    # Optimal/feasible, so get the solution
    print(&amp;quot;Solution value: &amp;quot;)
    print(prob.solution.get_objective_value())

    # get the configuration
    x_res = prob.solution.get_values(names)
    for x_name, val in zip(names, x_res):
        if val &amp;gt; 0:
            print(x_name, val)
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;step-3-generate-lazy-constraints&#34;&gt;(Step 3) Generate lazy constraints&lt;/h4&gt;
&lt;p&gt;We&amp;rsquo;ve not managed the lazy constraints yet. To do this we will use a CPLEX &lt;code&gt;Callback&lt;/code&gt;. The &lt;code&gt;LazyConstraintCallback&lt;/code&gt; is called each time an optimal or integral solution is found. The implementation looks like this.&lt;/p&gt;
&lt;p&gt;To find new independent sets, we take the solution (potentially fractional) and use a greedy heuristic to first generate an independent set on the induced subgraph of the solution. We then expand on the independent set for the entire graph using another &lt;code&gt;greedy_expand&lt;/code&gt; procedure which uses the same logic as &lt;code&gt;greedy_init&lt;/code&gt; to grown the independent set.&lt;/p&gt;
&lt;p&gt;If there are no additional independent sets, no constraints are added and the solver terminates.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class LazyCallback(LazyConstraintCallback):
    &amp;quot;&amp;quot;&amp;quot;Lazy constraint callback to generate maximum independent sets on the fly.

    There are too many such constraints to make them all available to 
    CPLEX right away - and in any case, very few of them are valid.

    So generate them on the fly.
    &amp;quot;&amp;quot;&amp;quot;

    # Callback constructor.
    #
    # Any needed fields are set externally after registering the callback.
    def __init__(self, env):
        super().__init__(env)

    def __call__(self):

        values = self.get_values(self.names)

        # Any node with non-zero value is considered as part of the set
        curr_solution = [int(name[1:]) for name, val in zip(self.names, values) if val &amp;gt;= 0.001]
        print(&amp;quot;Current solution: &amp;quot;, curr_solution)

        # Look to generate all independent sets that would cut off the (fractional)
        # value. To do this, first induce a subgraph - and for each node, built a
        #
        subG = self.G.subgraph(curr_solution)
        sub_ind_set = greedy_init(subG)
        max_ind_sets = [greedy_expand(self.G, sset) for sset in sub_ind_set]

        for iset in max_ind_sets:

            con_vars = [func(i) for i in iset]
            coeffs = [1.0] * len(con_vars)
            lhs = cplex.SparsePair(con_vars, coeffs)
            self.add(constraint=lhs, rhs=1.0, sense=&#39;L&#39;)

&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The callback must be registered with the problem instance and any variables passed as attributes as so:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from cplex.callbacks import LazyConstraintCallback

# register callbacks to generate additional independent sets on the fly
lazycb = prob.register_callback(LazyCallback)

# pass any arguments as class attributes
lazycb.names = names
lazycb.G = G
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For completeness, here is what the &lt;code&gt;greedy_expand&lt;/code&gt; function does&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def greedy_expand(G, init_set):

    R = G.copy()
    neigh = [n for i in init_set for n in R.neighbors(i)]
    R.remove_nodes_from(init_set)
    R.remove_nodes_from(neigh)
    if R.number_of_nodes() != 0:
        x = get_min_degree_vertex(R)
    while R.number_of_nodes() != 0:
        neigh2 = [m for m in R.neighbors(x)]
        R.remove_node(x)
        init_set.append(x)
        R.remove_nodes_from(neigh2)
        if R.number_of_nodes() != 0:
            x = get_min_degree_vertex(R)

    return init_set
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;putting-it-all-together&#34;&gt;Putting it all together&lt;/h4&gt;
&lt;p&gt;Running this all together as shown in this 
&lt;a href=&#34;https://gist.github.com/rahulnair23/ef3c14a3f08afdf0840459e10969eda8&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gist&lt;/a&gt;
&lt;script type=&#34;application/javascript&#34; src=&#34;https://gist.github.com/rahulnair23/ef3c14a3f08afdf0840459e10969eda8.js&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;gives the following output:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;Constraint: Maximum independent set. (18 constraints)
Version identifier: 12.10.0.0 | 2019-11-26 | 843d4de
CPXPARAM_Read_DataCheck                          1
Warning: Control callbacks may disable some MIP features.
Lazy constraint(s) or lazy constraint/branch callback is present.
    Disabling dual reductions (CPX_PARAM_REDUCE) in presolve.
    Disabling non-linear reductions (CPX_PARAM_PRELINEAR) in presolve.
    Disabling presolve reductions that prevent crushing forms.
         Disabling repeat represolve because of lazy constraint/incumbent callback.
Tried aggregator 1 time.
MIP Presolve eliminated 6 rows and 0 columns.
Reduced MIP has 12 rows, 18 columns, and 72 nonzeros.
Reduced MIP has 0 binaries, 0 generals, 0 SOSs, and 0 indicators.
Presolve time = 0.00 sec. (0.02 ticks)
MIP emphasis: balance optimality and feasibility.
MIP search method: traditional branch-and-cut.
Parallel mode: none, using 1 thread.
Root relaxation solution time = 0.00 sec. (0.01 ticks)
Current solution:  [5, 7, 8, 14, 16, 17]
Current solution:  [4, 10, 11, 13]
Current solution:  [0, 6, 8, 10, 11]
Current solution:  [4, 6, 8, 10, 11, 16]
Current solution:  [0, 2, 4, 5, 6, 8]
Current solution:  [6, 7, 8]
Current solution:  [6, 7, 8]

        Nodes                                         Cuts/
   Node  Left     Objective  IInf  Best Integer    Best Bound    ItCnt     Gap         Variable B NodeID Parent  Depth

*     0     0      integral     0        3.0000        6.0000        8  100.00%                        0             0
Elapsed time = 0.02 sec. (0.16 ticks, tree = 0.00 MB, solutions = 1)

User cuts applied:  17

Root node processing (before b&amp;amp;c):
  Real time             =    0.02 sec. (0.16 ticks)
Sequential b&amp;amp;c:
  Real time             =    0.00 sec. (0.00 ticks)
                          ------------
Total (root+branch&amp;amp;cut) =    0.02 sec. (0.16 ticks)
Status:MIP_optimal
Solution value: 
3.0
x6 1.0
x7 1.0
x8 1.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This identified one of the 3-vertex cliques, which is the maximum. The program started with 18 maximum independent sets generated greedily. It generated a further 17 user cuts one for each new independent set that were constructed on the fly. For a graph with $n$ nodes, there can be at most $3^{n/3}$ maximum independent sets although most have far fewer. For our 18 node graph, that would be 729 sets. In this greedy solution method, we got away with generating just 35.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
